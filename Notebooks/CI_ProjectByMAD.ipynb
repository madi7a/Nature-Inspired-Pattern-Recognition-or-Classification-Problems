{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mq_jbrhxyrHE"
      },
      "outputs": [],
      "source": [
        "import kagglehub\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV, StratifiedKFold\n",
        "from sklearn.preprocessing import StandardScaler, OneHotEncoder, LabelEncoder\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, make_scorer\n",
        "import time\n",
        "import random\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.metrics import make_scorer, f1_score\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib.animation import FuncAnimation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "2MP9zFPPxp88"
      },
      "outputs": [],
      "source": [
        "path = kagglehub.dataset_download(\"wenruliu/adult-income-dataset\")\n",
        "import os\n",
        "csv_file_path = None\n",
        "expected_file = 'adult.csv'\n",
        "for root, g, files in os.walk(path):\n",
        "    if expected_file in files:\n",
        "        csv_file_path = os.path.join(root, expected_file)\n",
        "        break"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "axPf2TJQ0f_l",
        "outputId": "6da32c92-32ed-462a-f7e9-8fcb9ebe1543"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(48842, 15)"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df = pd.read_csv(csv_file_path, na_values=['?'])\n",
        "df.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "lK7pNiQ-0pBj",
        "outputId": "44c534df-603a-4d9c-9a98-f0b60530ac15"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>age</th>\n",
              "      <th>workclass</th>\n",
              "      <th>fnlwgt</th>\n",
              "      <th>education</th>\n",
              "      <th>educational-num</th>\n",
              "      <th>marital-status</th>\n",
              "      <th>occupation</th>\n",
              "      <th>relationship</th>\n",
              "      <th>race</th>\n",
              "      <th>gender</th>\n",
              "      <th>capital-gain</th>\n",
              "      <th>capital-loss</th>\n",
              "      <th>hours-per-week</th>\n",
              "      <th>native-country</th>\n",
              "      <th>income</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>25</td>\n",
              "      <td>Private</td>\n",
              "      <td>226802</td>\n",
              "      <td>11th</td>\n",
              "      <td>7</td>\n",
              "      <td>Never-married</td>\n",
              "      <td>Machine-op-inspct</td>\n",
              "      <td>Own-child</td>\n",
              "      <td>Black</td>\n",
              "      <td>Male</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>40</td>\n",
              "      <td>United-States</td>\n",
              "      <td>&lt;=50K</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>38</td>\n",
              "      <td>Private</td>\n",
              "      <td>89814</td>\n",
              "      <td>HS-grad</td>\n",
              "      <td>9</td>\n",
              "      <td>Married-civ-spouse</td>\n",
              "      <td>Farming-fishing</td>\n",
              "      <td>Husband</td>\n",
              "      <td>White</td>\n",
              "      <td>Male</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>50</td>\n",
              "      <td>United-States</td>\n",
              "      <td>&lt;=50K</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>28</td>\n",
              "      <td>Local-gov</td>\n",
              "      <td>336951</td>\n",
              "      <td>Assoc-acdm</td>\n",
              "      <td>12</td>\n",
              "      <td>Married-civ-spouse</td>\n",
              "      <td>Protective-serv</td>\n",
              "      <td>Husband</td>\n",
              "      <td>White</td>\n",
              "      <td>Male</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>40</td>\n",
              "      <td>United-States</td>\n",
              "      <td>&gt;50K</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>44</td>\n",
              "      <td>Private</td>\n",
              "      <td>160323</td>\n",
              "      <td>Some-college</td>\n",
              "      <td>10</td>\n",
              "      <td>Married-civ-spouse</td>\n",
              "      <td>Machine-op-inspct</td>\n",
              "      <td>Husband</td>\n",
              "      <td>Black</td>\n",
              "      <td>Male</td>\n",
              "      <td>7688</td>\n",
              "      <td>0</td>\n",
              "      <td>40</td>\n",
              "      <td>United-States</td>\n",
              "      <td>&gt;50K</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>18</td>\n",
              "      <td>NaN</td>\n",
              "      <td>103497</td>\n",
              "      <td>Some-college</td>\n",
              "      <td>10</td>\n",
              "      <td>Never-married</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Own-child</td>\n",
              "      <td>White</td>\n",
              "      <td>Female</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>30</td>\n",
              "      <td>United-States</td>\n",
              "      <td>&lt;=50K</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   age  workclass  fnlwgt     education  educational-num      marital-status  \\\n",
              "0   25    Private  226802          11th                7       Never-married   \n",
              "1   38    Private   89814       HS-grad                9  Married-civ-spouse   \n",
              "2   28  Local-gov  336951    Assoc-acdm               12  Married-civ-spouse   \n",
              "3   44    Private  160323  Some-college               10  Married-civ-spouse   \n",
              "4   18        NaN  103497  Some-college               10       Never-married   \n",
              "\n",
              "          occupation relationship   race  gender  capital-gain  capital-loss  \\\n",
              "0  Machine-op-inspct    Own-child  Black    Male             0             0   \n",
              "1    Farming-fishing      Husband  White    Male             0             0   \n",
              "2    Protective-serv      Husband  White    Male             0             0   \n",
              "3  Machine-op-inspct      Husband  Black    Male          7688             0   \n",
              "4                NaN    Own-child  White  Female             0             0   \n",
              "\n",
              "   hours-per-week native-country income  \n",
              "0              40  United-States  <=50K  \n",
              "1              50  United-States  <=50K  \n",
              "2              40  United-States   >50K  \n",
              "3              40  United-States   >50K  \n",
              "4              30  United-States  <=50K  "
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sAGc1YMh0rfz",
        "outputId": "6995c8c2-dee1-43ad-d39b-0faa00e2dcde"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 48842 entries, 0 to 48841\n",
            "Data columns (total 15 columns):\n",
            " #   Column           Non-Null Count  Dtype \n",
            "---  ------           --------------  ----- \n",
            " 0   age              48842 non-null  int64 \n",
            " 1   workclass        46043 non-null  object\n",
            " 2   fnlwgt           48842 non-null  int64 \n",
            " 3   education        48842 non-null  object\n",
            " 4   educational-num  48842 non-null  int64 \n",
            " 5   marital-status   48842 non-null  object\n",
            " 6   occupation       46033 non-null  object\n",
            " 7   relationship     48842 non-null  object\n",
            " 8   race             48842 non-null  object\n",
            " 9   gender           48842 non-null  object\n",
            " 10  capital-gain     48842 non-null  int64 \n",
            " 11  capital-loss     48842 non-null  int64 \n",
            " 12  hours-per-week   48842 non-null  int64 \n",
            " 13  native-country   47985 non-null  object\n",
            " 14  income           48842 non-null  object\n",
            "dtypes: int64(6), object(9)\n",
            "memory usage: 5.6+ MB\n"
          ]
        }
      ],
      "source": [
        "df.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 555
        },
        "id": "GLwQPOWD0yH_",
        "outputId": "5949cd89-4447-4cd6-ce60-85efeb751f00"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "age                   0\n",
              "workclass          2799\n",
              "fnlwgt                0\n",
              "education             0\n",
              "educational-num       0\n",
              "marital-status        0\n",
              "occupation         2809\n",
              "relationship          0\n",
              "race                  0\n",
              "gender                0\n",
              "capital-gain          0\n",
              "capital-loss          0\n",
              "hours-per-week        0\n",
              "native-country      857\n",
              "income                0\n",
              "dtype: int64"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df.isnull().sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "np.int64(52)"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df.duplicated().sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "802L29Fxx0sz",
        "outputId": "d479134d-e557-4617-e5ad-c7d81599db24"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "X_train shape: (4000, 13)\n",
            "y_train shape: (4000,)\n",
            "X_test shape: (1000, 13)\n",
            "y_test shape: (1000,)\n"
          ]
        }
      ],
      "source": [
        "df_processed = df.copy()\n",
        "\n",
        "SUBSET_SIZE = 5000\n",
        "\n",
        "df_processed = df_processed.sample(n=SUBSET_SIZE, random_state=42).reset_index(drop=True)\n",
        "\n",
        "TARGET_COLUMN = 'income'\n",
        "NEW_TARGET_NAME = 'Outcome'\n",
        "\n",
        "y = df_processed[TARGET_COLUMN]\n",
        "X = df_processed.drop(TARGET_COLUMN, axis=1)\n",
        "COLUMNS_TO_DROP = ['fnlwgt']\n",
        "if 'ID' in X.columns:\n",
        "    COLUMNS_TO_DROP.append('ID')\n",
        "if 'policy_id' in X.columns:\n",
        "    COLUMNS_TO_DROP.append('policy_id')\n",
        "\n",
        "X = X.drop(columns=COLUMNS_TO_DROP, errors='ignore')\n",
        "\n",
        "y = y.rename(NEW_TARGET_NAME)\n",
        "\n",
        "if y.dtype == 'object':\n",
        "    le = LabelEncoder()\n",
        "    y = pd.Series(le.fit_transform(y), name=NEW_TARGET_NAME, index=y.index)\n",
        "\n",
        "numerical_features = X.select_dtypes(include=np.number).columns.tolist()\n",
        "categorical_features = X.select_dtypes(include=['object', 'category']).columns.tolist()\n",
        "\n",
        "all_identified_features = numerical_features + categorical_features\n",
        "if len(all_identified_features) != X.shape[1]:\n",
        "    print(\"Warning: Not all columns were classified as numerical or categorical!\")\n",
        "    print(\"Unclassified columns:\", [col for col in X.columns if col not in all_identified_features])\n",
        "\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
        "\n",
        "print(\"X_train shape:\", X_train.shape)\n",
        "print(\"y_train shape:\", y_train.shape)\n",
        "print(\"X_test shape:\", X_test.shape)\n",
        "print(\"y_test shape:\", y_test.shape)\n",
        "\n",
        "\n",
        "numerical_pipeline = Pipeline([\n",
        "    ('imputer', SimpleImputer(strategy='median')),\n",
        "    ('scaler', StandardScaler())\n",
        "])\n",
        "\n",
        "categorical_pipeline = Pipeline([\n",
        "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
        "    ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
        "])\n",
        "\n",
        "transformers = []\n",
        "if numerical_features:\n",
        "    transformers.append(('num', numerical_pipeline, numerical_features))\n",
        "if categorical_features:\n",
        "    transformers.append(('cat', categorical_pipeline, categorical_features))\n",
        "\n",
        "if not transformers:\n",
        "     raise ValueError(\"No numerical or categorical features identified for preprocessing.\")\n",
        "\n",
        "\n",
        "preprocessor = ColumnTransformer(transformers=transformers, remainder='passthrough')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "vvk2YzkRx9PD"
      },
      "outputs": [],
      "source": [
        "def evaluate_classifier(model, X, y):\n",
        "    y_pred = model.predict(X)\n",
        "    if y.dtype not in [np.number, np.int64, np.float64]:\n",
        "         print(f\"Warning: Target labels are not numerical (dtype is {y.dtype}). Cannot calculate ROC AUC.\")\n",
        "         auc = np.nan\n",
        "    else:\n",
        "        try:\n",
        "            if hasattr(model, 'predict_proba'):\n",
        "                 y_prob = model.predict_proba(X)[:, 1]\n",
        "                 if len(np.unique(y)) == 2:\n",
        "                     auc = roc_auc_score(y, y_prob)\n",
        "                 else:\n",
        "                     auc = np.nan\n",
        "\n",
        "            else:\n",
        "                 auc = np.nan\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Warning: Could not calculate ROC AUC. Error: {e}\")\n",
        "            auc = np.nan\n",
        "\n",
        "    metrics = {\n",
        "        'accuracy': accuracy_score(y, y_pred),\n",
        "        'precision': precision_score(y, y_pred),\n",
        "        'recall': recall_score(y, y_pred),\n",
        "        'f1_score': f1_score(y, y_pred),\n",
        "        'roc_auc': auc\n",
        "    }\n",
        "    return metrics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8nSWijduyAIr",
        "outputId": "f32bfba7-4e7d-472c-b6f2-3465bed5f114"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'C': 1.0, 'break_ties': False, 'cache_size': 200, 'class_weight': None, 'coef0': 0.0, 'decision_function_shape': 'ovr', 'degree': 3, 'gamma': 'scale', 'kernel': 'rbf', 'max_iter': -1, 'probability': True, 'random_state': 42, 'shrinking': True, 'tol': 0.001, 'verbose': False}\n",
            "\n",
            "Baseline model training time: 5.0983 seconds\n",
            "accuracy: 0.8700\n",
            "precision: 0.7865\n",
            "recall: 0.6292\n",
            "f1_score: 0.6991\n",
            "roc_auc: 0.9041\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\Madiha\\AppData\\Local\\Temp\\ipykernel_36608\\1545063328.py:3: DeprecationWarning: Converting `np.inexact` or `np.floating` to a dtype is deprecated. The current result is `float64` which is not strictly correct.\n",
            "  if y.dtype not in [np.number, np.int64, np.float64]:\n"
          ]
        }
      ],
      "source": [
        "svm_baseline_estimator = SVC(random_state=42, probability=True)\n",
        "\n",
        "baseline_pipeline = Pipeline([\n",
        "    ('preprocessor', preprocessor),\n",
        "    ('svc', svm_baseline_estimator)\n",
        "])\n",
        "\n",
        "print(baseline_pipeline.named_steps['svc'].get_params())\n",
        "\n",
        "start_time = time.time()\n",
        "baseline_pipeline.fit(X_train, y_train)\n",
        "train_time_baseline = time.time() - start_time\n",
        "\n",
        "print(f\"\\nBaseline model training time: {train_time_baseline:.4f} seconds\")\n",
        "\n",
        "baseline_metrics = evaluate_classifier(baseline_pipeline, X_test, y_test)\n",
        "\n",
        "for metric, value in baseline_metrics.items():\n",
        "    print(f\"{metric}: {value:.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_0RyAX7pyDVN",
        "outputId": "2150007c-4a3a-46d0-9b52-1fe5acba22ec"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "--- Traditional Tuning: Grid Search for SVM Parameters ---\n",
            "{'svc__C': [0.1, 1, 10], 'svc__gamma': [0.01, 0.1, 'scale'], 'svc__kernel': ['rbf']}\n",
            "Fitting 3 folds for each of 9 candidates, totalling 27 fits\n",
            "{'svc__C': 10, 'svc__gamma': 0.01, 'svc__kernel': 'rbf'}\n",
            "Best cross-validation score (make_scorer(f1_score, response_method='predict', average=binary)): 0.6572\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\Madiha\\AppData\\Local\\Temp\\ipykernel_36608\\1545063328.py:3: DeprecationWarning: Converting `np.inexact` or `np.floating` to a dtype is deprecated. The current result is `float64` which is not strictly correct.\n",
            "  if y.dtype not in [np.number, np.int64, np.float64]:\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "accuracy: 0.8660\n",
            "precision: 0.7650\n",
            "recall: 0.6375\n",
            "f1_score: 0.6955\n",
            "roc_auc: 0.9080\n"
          ]
        }
      ],
      "source": [
        "print(\"\\n--- Traditional Tuning: Grid Search for SVM Parameters ---\")\n",
        "\n",
        "svm_gs_estimator = SVC(random_state=42, probability=True)\n",
        "\n",
        "gs_pipeline = Pipeline([\n",
        "    ('preprocessor', preprocessor),\n",
        "    ('svc', svm_gs_estimator)\n",
        "])\n",
        "\n",
        "param_grid = {\n",
        "    'svc__C': [0.1, 1, 10],\n",
        "    'svc__gamma': [0.01, 0.1, 'scale'],\n",
        "    'svc__kernel': ['rbf']\n",
        "}\n",
        "\n",
        "print(param_grid)\n",
        "\n",
        "cv_strategy = StratifiedKFold(n_splits=3, shuffle=True, random_state=42)\n",
        "\n",
        "grid_search = GridSearchCV(\n",
        "    estimator=gs_pipeline,\n",
        "    param_grid=param_grid,\n",
        "    cv=cv_strategy,\n",
        "    scoring='f1',\n",
        "    n_jobs=-1,\n",
        "    verbose=2\n",
        ")\n",
        "\n",
        "start_time = time.time()\n",
        "grid_search.fit(X_train, y_train)\n",
        "tuning_time_gs = time.time() - start_time\n",
        "\n",
        "best_params_gs = grid_search.best_params_\n",
        "best_svm_model_gs = grid_search.best_estimator_\n",
        "\n",
        "print(best_params_gs)\n",
        "print(f\"Best cross-validation score ({grid_search.scorer_}): {grid_search.best_score_:.4f}\")\n",
        "\n",
        "tuned_metrics_gs = evaluate_classifier(best_svm_model_gs, X_test, y_test)\n",
        "\n",
        "for metric, value in tuned_metrics_gs.items():\n",
        "    print(f\"{metric}: {value:.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1KxmBCJoyHO1",
        "outputId": "8aec3739-575b-4f71-94f5-8aee62502fbc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Metric         | Baseline SVM | Grid Search Tuned SVM\n",
            "---------------------------------------------------\n",
            "accuracy       | 0.8700     | 0.8660\n",
            "f1_score       | 0.6991     | 0.6955\n",
            "precision      | 0.7865     | 0.7650\n",
            "recall         | 0.6292     | 0.6375\n",
            "roc_auc        | 0.9041     | 0.9080\n",
            "\n",
            "Tuning Time (seconds): Baseline: 5.0983, Grid Search: 43.5658\n"
          ]
        }
      ],
      "source": [
        "print(\"Metric         | Baseline SVM | Grid Search Tuned SVM\")\n",
        "print(\"---------------------------------------------------\")\n",
        "all_metrics = sorted(list(set(baseline_metrics.keys()) | set(tuned_metrics_gs.keys())))\n",
        "\n",
        "for metric in all_metrics:\n",
        "    baseline_val = baseline_metrics.get(metric, np.nan)\n",
        "    tuned_gs_val = tuned_metrics_gs.get(metric, np.nan)\n",
        "\n",
        "    baseline_str = f\"{baseline_val:.4f}\" if pd.notna(baseline_val) else \"N/A     \"\n",
        "    tuned_gs_str = f\"{tuned_gs_val:.4f}\" if pd.notna(tuned_gs_val) else \"N/A     \"\n",
        "\n",
        "    print(f\"{metric:<14} | {baseline_str}     | {tuned_gs_str}\")\n",
        "\n",
        "print(f\"\\nTuning Time (seconds): Baseline: {train_time_baseline:.4f}, Grid Search: {tuning_time_gs:.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {},
      "outputs": [],
      "source": [
        "N_POPULATION = 20\n",
        "N_ITERATIONS = 10\n",
        "MUTATION_RATE = 0.5\n",
        "MIN_VAL_C = 0.1\n",
        "MAX_VAL_C = 100\n",
        "MIN_VAL_GAMMA = 0.0001\n",
        "MAX_VAL_GAMMA = 1\n",
        "MUTATION_STRENGTH = .1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.3965703784017728\n"
          ]
        }
      ],
      "source": [
        "print(random.random())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [],
      "source": [
        "def random_chromosome():\n",
        "    return [random.uniform(MIN_VAL_C, MAX_VAL_C), random.uniform(MIN_VAL_GAMMA, MAX_VAL_GAMMA)] "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[58.286414808827644, 0.5589024143552049]\n"
          ]
        }
      ],
      "source": [
        "chromosome = random_chromosome()\n",
        "print( chromosome)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def fitness(chromosome, X, y):\n",
        "    C, gamma = chromosome[0], chromosome[1]\n",
        "\n",
        "    model = Pipeline([\n",
        "        ('preprocessor', preprocessor),\n",
        "        ('svc', SVC(C=C, gamma=gamma, kernel='rbf'))\n",
        "    ])\n",
        "    scores = cross_val_score(model, X, y, cv=3, scoring='f1_macro')\n",
        "\n",
        "    return scores.mean()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {},
      "outputs": [],
      "source": [
        "def create_population(N_POPULATION):\n",
        "    pop = []\n",
        "    for _ in range(N_POPULATION): \n",
        "        individual = random_chromosome()\n",
        "        pop.append(individual)\n",
        "    return pop"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {},
      "outputs": [],
      "source": [
        "def evaluate_population(pop, X, y):\n",
        "    evaluated = []\n",
        "    for indiv in pop:\n",
        "        fit = fitness(indiv, X, y)\n",
        "        evaluated.append([indiv[0], indiv[1], fit])\n",
        "    return evaluated\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {},
      "outputs": [],
      "source": [
        "pop_evaluated = evaluate_population(pop, X_train, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 121,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[[21.228110741887594, 0.7082897999156881, np.float64(0.79125)],\n",
              " [49.50892985889862, 0.1869475922769497, np.float64(0.8192499999999999)],\n",
              " [45.03372230631889, 0.8538861509445128, np.float64(0.786)],\n",
              " [15.317167896224023, 0.4965294888390049, np.float64(0.80625)],\n",
              " [21.515737555957617, 0.018493573351651815, np.float64(0.8525)],\n",
              " [77.5070096017225, 0.46616730340731694, np.float64(0.7982500000000001)],\n",
              " [46.72013201175253, 0.6868134961036066, np.float64(0.7932499999999999)],\n",
              " [71.91639037101667, 0.2360559305109132, np.float64(0.81225)],\n",
              " [4.785157692471482, 0.28627143697648566, np.float64(0.8352499999999999)],\n",
              " [99.74242166956603, 0.05512590376546943, np.float64(0.8227499999999999)]]"
            ]
          },
          "execution_count": 121,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "pop_evaluated"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {},
      "outputs": [],
      "source": [
        "def tournament_selection(pop, tournament_size=5):\n",
        "    \n",
        "    tournament = random.sample(pop, tournament_size)\n",
        "    \n",
        "    winner = max(tournament, key=lambda x: x[2])\n",
        "    \n",
        "    return winner"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[87.93661433899456, 0.33453418484075664, np.float64(0.8074999999999999)]"
            ]
          },
          "execution_count": 57,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "winn = tournament_selection(pop_evaluated)\n",
        "winn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {},
      "outputs": [],
      "source": [
        "def roulette_wheel_selection(pop):\n",
        "    total_fitness = sum(individual[2] for individual in pop)\n",
        "    \n",
        "    pick = random.uniform(0, total_fitness)\n",
        "    current = 0\n",
        "    \n",
        "    for individual in pop:\n",
        "        current += individual[2]\n",
        "        if current > pick:\n",
        "            return individual\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 96,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[91.7640111568729, 0.5088838376373818, np.float64(0.79775)]"
            ]
          },
          "execution_count": 96,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "ind = roulette_wheel_selection(pop_evaluated)\n",
        "ind"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {},
      "outputs": [],
      "source": [
        "def rank_selection(pop):\n",
        "    ranked_pop = sorted(pop, key=lambda x: x[2], reverse=True)\n",
        "    \n",
        "    total_rank = sum(range(1, len(pop) + 1))\n",
        "    pick = random.uniform(0, total_rank)\n",
        "    current_rank = 0\n",
        "    \n",
        "    for i, individual in enumerate(ranked_pop):\n",
        "        current_rank += (i + 1)\n",
        "        if current_rank >= pick:\n",
        "            return individual\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 84,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[44.54608996572458, 0.388042596694855, np.float64(0.8067499999999999)]"
            ]
          },
          "execution_count": 84,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "indd = rank_selection(pop_evaluated)\n",
        "indd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {},
      "outputs": [],
      "source": [
        "def stochastic_universal_sampling(pop, num_parents=2):\n",
        "    total_fitness = sum(individual[2] for individual in pop)\n",
        "    \n",
        "    # Divide the fitness sum into equal intervals\n",
        "    distance = total_fitness / num_parents\n",
        "    start_point = random.uniform(0, distance)\n",
        "    \n",
        "    selected_parents = []\n",
        "    current_point = start_point\n",
        "    for _ in range(num_parents):\n",
        "        total = 0\n",
        "        for individual in pop:\n",
        "            total += individual[2]\n",
        "            if total >= current_point:\n",
        "                selected_parents.append(individual)\n",
        "                current_point += distance\n",
        "                break\n",
        "    \n",
        "    return selected_parents\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 98,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[91.7640111568729, 0.5088838376373818, np.float64(0.79775)]"
            ]
          },
          "execution_count": 98,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "inddd = stochastic_universal_sampling(pop_evaluated)\n",
        "inddd[1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {},
      "outputs": [],
      "source": [
        "def uniform_mutation(individual):\n",
        "    c, gamma, fitness = individual\n",
        "\n",
        "    if random.random() < MUTATION_RATE:\n",
        "        c = random.uniform(MIN_VAL_C, MAX_VAL_C)\n",
        "        gamma = random.uniform(MIN_VAL_GAMMA, MAX_VAL_GAMMA)\n",
        "        return [c, gamma, 0]\n",
        "\n",
        "    return individual "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 100,
      "metadata": {},
      "outputs": [],
      "source": [
        "mutated = uniform_mutation(indd)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 101,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[35.1105400227239, 0.38665807434407556, 0]"
            ]
          },
          "execution_count": 101,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "mutated"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {},
      "outputs": [],
      "source": [
        "def creep_mutation(individual):\n",
        "    c, gamma, fitness = individual\n",
        "\n",
        "    if random.random() < MUTATION_RATE:\n",
        "        c += random.uniform(-0.05, 0.05)\n",
        "        gamma += random.uniform(-0.05, 0.05)\n",
        "        \n",
        "        c = min(max(c, MIN_VAL_C), MAX_VAL_C)\n",
        "        gamma = min(max(gamma, MIN_VAL_GAMMA), MAX_VAL_GAMMA)\n",
        "        return [c, gamma, 0]\n",
        "    \n",
        "    return individual\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 110,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[44.54608996572458, 0.388042596694855, np.float64(0.8067499999999999)]\n"
          ]
        }
      ],
      "source": [
        "print(creep_mutation(indd))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {},
      "outputs": [],
      "source": [
        "def gaussian_mutation(individual):\n",
        "    c, gamma, fitness = individual\n",
        "\n",
        "    if random.random() < MUTATION_RATE:\n",
        "        c = min(max(c + random.gauss(0, MUTATION_STRENGTH), MIN_VAL_C), MAX_VAL_C)\n",
        "        gamma = min(max(gamma + random.gauss(0, MUTATION_STRENGTH), MIN_VAL_GAMMA), MAX_VAL_GAMMA)\n",
        "        return [c, gamma, 0]\n",
        "\n",
        "    return individual\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 114,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[44.39748879297673, 0.35228535610403444, 0]\n"
          ]
        }
      ],
      "source": [
        "print(gaussian_mutation(indd))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {},
      "outputs": [],
      "source": [
        "def uniform_crossover(parent1, parent2):\n",
        "    c1, gamma1, _ = parent1\n",
        "    c2, gamma2, _ = parent2\n",
        "    \n",
        "    new_c = c1 if random.random() < 0.5 else c2\n",
        "    new_gamma = gamma1 if random.random() < 0.5 else gamma2\n",
        "    \n",
        "    return [new_c, new_gamma, 0]  \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {},
      "outputs": [],
      "source": [
        "def arithmetic_crossover(parent1, parent2, alpha=0.5):\n",
        "    c1, gamma1, _ = parent1\n",
        "    c2, gamma2, _ = parent2\n",
        "\n",
        "    new_c = alpha * c1 + (1 - alpha) * c2\n",
        "    new_gamma = alpha * gamma1 + (1 - alpha) * gamma2\n",
        "\n",
        "    return [new_c, new_gamma, 0]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {},
      "outputs": [],
      "source": [
        "def calculate_crowding_distance(pop):\n",
        "    # Sort by fitness ascending\n",
        "    sorted_pop = sorted(pop, key=lambda x: x[2])\n",
        "    distances = [0] * len(pop)\n",
        "    for i in range(1, len(pop) - 1):\n",
        "        distances[i] = abs(sorted_pop[i + 1][2] - sorted_pop[i - 1][2])\n",
        "    # Boundary individuals get max distance to keep diversity\n",
        "    distances[0] = distances[1]\n",
        "    distances[-1] = distances[-2]\n",
        "    # Return dictionary: {chromosome_tuple: distance} for quick lookup\n",
        "    dist_dict = {tuple(indiv[:2]): dist for indiv, dist in zip(sorted_pop, distances)}\n",
        "    return dist_dict"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def genetic_algorithm(\n",
        "    X, y,\n",
        "    selection_method,\n",
        "    mutation_method,\n",
        "    crossover_method,\n",
        "    n_population=N_POPULATION,\n",
        "    n_iterations=N_ITERATIONS,\n",
        "    seed=None\n",
        "):\n",
        "    if seed is not None:\n",
        "        random.seed(seed)\n",
        "        np.random.seed(seed)\n",
        "\n",
        "    all_individuals = []\n",
        "    population = create_population(n_population)\n",
        "    population = evaluate_population(population, X, y)\n",
        "\n",
        "    # Save initial generation with diversity\n",
        "    crowd_distances = calculate_crowding_distance(population)\n",
        "    for indiv in population:\n",
        "        all_individuals.append({\n",
        "            'generation': 0,\n",
        "            'C': indiv[0],\n",
        "            'gamma': indiv[1],\n",
        "            'fitness': indiv[2],\n",
        "            'diversity': crowd_distances.get((indiv[0], indiv[1]), 0),\n",
        "            'seed': seed\n",
        "        })\n",
        "\n",
        "    best_solution = max(population, key=lambda x: x[2])\n",
        "\n",
        "    for gen in range(1, n_iterations + 1):\n",
        "        new_population = []\n",
        "        while len(new_population) < n_population:\n",
        "            # Parent selection\n",
        "            if selection_method == 'tournament':\n",
        "                parent1 = tournament_selection(population)\n",
        "                parent2 = tournament_selection(population)\n",
        "            elif selection_method == 'roulette':\n",
        "                parent1 = roulette_wheel_selection(population)\n",
        "                parent2 = roulette_wheel_selection(population)\n",
        "            elif selection_method == 'rank':\n",
        "                parent1 = rank_selection(population)\n",
        "                parent2 = rank_selection(population)\n",
        "            elif selection_method == 'sus':\n",
        "                parents = stochastic_universal_sampling(population, 2)\n",
        "                parent1, parent2 = parents[0], parents[1]\n",
        "            else:\n",
        "                raise ValueError(\"Unknown selection method\")\n",
        "\n",
        "            # Crossover\n",
        "            if crossover_method == 'uniform':\n",
        "                child = uniform_crossover(parent1, parent2)\n",
        "            elif crossover_method == 'arithmetic':\n",
        "                child = arithmetic_crossover(parent1, parent2)\n",
        "            else:\n",
        "                raise ValueError(\"Unknown crossover method\")\n",
        "\n",
        "            # Mutation\n",
        "            if mutation_method == 'uniform':\n",
        "                child = uniform_mutation(child)\n",
        "            elif mutation_method == 'creep':\n",
        "                child = creep_mutation(child)\n",
        "            elif mutation_method == 'gaussian':\n",
        "                child = gaussian_mutation(child)\n",
        "            else:\n",
        "                raise ValueError(\"Unknown mutation method\")\n",
        "\n",
        "            \n",
        "            child[2] = fitness(child, X, y)\n",
        "            new_population.append(child)\n",
        "\n",
        "        population = new_population\n",
        "\n",
        "       \n",
        "        crowd_distances = calculate_crowding_distance(population)\n",
        "\n",
        "        \n",
        "        for indiv in population:\n",
        "            all_individuals.append({\n",
        "                'generation': gen,\n",
        "                'C': indiv[0],\n",
        "                'gamma': indiv[1],\n",
        "                'fitness': indiv[2],\n",
        "                'diversity': crowd_distances.get((indiv[0], indiv[1]), 0),\n",
        "                'seed': seed\n",
        "            })\n",
        "\n",
        "        current_best = max(population, key=lambda x: x[2])\n",
        "        if current_best[2] > best_solution[2]:\n",
        "            best_solution = current_best\n",
        "\n",
        "        print(f\"Gen {gen} | Best Fitness: {best_solution[2]:.4f}\")\n",
        "\n",
        "    return best_solution, all_individuals\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {},
      "outputs": [],
      "source": [
        "def run_experiments(X, y, n_runs=30):\n",
        "    seeds = list(range(1000, 1000 + n_runs))\n",
        "    experiment_data = []\n",
        "    for run_seed in seeds:\n",
        "        print(f\"\\nRun with seed {run_seed}\")\n",
        "        best, all_indivs = genetic_algorithm(\n",
        "            X, y,\n",
        "            selection_method='tournament',\n",
        "            mutation_method='creep',\n",
        "            crossover_method='uniform',\n",
        "            n_population=N_POPULATION,\n",
        "            n_iterations=N_ITERATIONS,\n",
        "            seed=run_seed\n",
        "        )\n",
        "        experiment_data.extend(all_indivs)\n",
        "    return experiment_data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Run with seed 1000\n",
            "Gen 1 | Best Fitness: 0.8492\n",
            "Gen 2 | Best Fitness: 0.8492\n",
            "Gen 3 | Best Fitness: 0.8540\n",
            "Gen 4 | Best Fitness: 0.8540\n",
            "Gen 5 | Best Fitness: 0.8540\n",
            "Gen 6 | Best Fitness: 0.8540\n",
            "Gen 7 | Best Fitness: 0.8540\n",
            "Gen 8 | Best Fitness: 0.8545\n",
            "Gen 9 | Best Fitness: 0.8545\n",
            "Gen 10 | Best Fitness: 0.8545\n",
            "\n",
            "Run with seed 1001\n",
            "Gen 1 | Best Fitness: 0.8538\n",
            "Gen 2 | Best Fitness: 0.8538\n",
            "Gen 3 | Best Fitness: 0.8538\n",
            "Gen 4 | Best Fitness: 0.8538\n",
            "Gen 5 | Best Fitness: 0.8538\n",
            "Gen 6 | Best Fitness: 0.8538\n",
            "Gen 7 | Best Fitness: 0.8538\n",
            "Gen 8 | Best Fitness: 0.8538\n",
            "Gen 9 | Best Fitness: 0.8538\n",
            "Gen 10 | Best Fitness: 0.8538\n",
            "\n",
            "Run with seed 1002\n",
            "Gen 1 | Best Fitness: 0.8417\n",
            "Gen 2 | Best Fitness: 0.8538\n",
            "Gen 3 | Best Fitness: 0.8548\n",
            "Gen 4 | Best Fitness: 0.8548\n",
            "Gen 5 | Best Fitness: 0.8548\n",
            "Gen 6 | Best Fitness: 0.8548\n",
            "Gen 7 | Best Fitness: 0.8548\n",
            "Gen 8 | Best Fitness: 0.8548\n",
            "Gen 9 | Best Fitness: 0.8548\n",
            "Gen 10 | Best Fitness: 0.8548\n",
            "\n",
            "Run with seed 1003\n",
            "Gen 1 | Best Fitness: 0.8545\n",
            "Gen 2 | Best Fitness: 0.8545\n",
            "Gen 3 | Best Fitness: 0.8545\n",
            "Gen 4 | Best Fitness: 0.8545\n",
            "Gen 5 | Best Fitness: 0.8545\n",
            "Gen 6 | Best Fitness: 0.8545\n",
            "Gen 7 | Best Fitness: 0.8545\n",
            "Gen 8 | Best Fitness: 0.8545\n",
            "Gen 9 | Best Fitness: 0.8550\n",
            "Gen 10 | Best Fitness: 0.8550\n",
            "\n",
            "Run with seed 1004\n",
            "Gen 1 | Best Fitness: 0.8475\n",
            "Gen 2 | Best Fitness: 0.8477\n",
            "Gen 3 | Best Fitness: 0.8482\n",
            "Gen 4 | Best Fitness: 0.8503\n",
            "Gen 5 | Best Fitness: 0.8510\n",
            "Gen 6 | Best Fitness: 0.8520\n",
            "Gen 7 | Best Fitness: 0.8523\n",
            "Gen 8 | Best Fitness: 0.8523\n",
            "Gen 9 | Best Fitness: 0.8523\n",
            "Gen 10 | Best Fitness: 0.8523\n",
            "\n",
            "Run with seed 1005\n",
            "Gen 1 | Best Fitness: 0.8515\n",
            "Gen 2 | Best Fitness: 0.8518\n",
            "Gen 3 | Best Fitness: 0.8528\n",
            "Gen 4 | Best Fitness: 0.8532\n",
            "Gen 5 | Best Fitness: 0.8533\n",
            "Gen 6 | Best Fitness: 0.8538\n",
            "Gen 7 | Best Fitness: 0.8538\n",
            "Gen 8 | Best Fitness: 0.8538\n",
            "Gen 9 | Best Fitness: 0.8538\n",
            "Gen 10 | Best Fitness: 0.8538\n",
            "\n",
            "Run with seed 1006\n",
            "Gen 1 | Best Fitness: 0.8480\n",
            "Gen 2 | Best Fitness: 0.8545\n",
            "Gen 3 | Best Fitness: 0.8545\n",
            "Gen 4 | Best Fitness: 0.8545\n",
            "Gen 5 | Best Fitness: 0.8545\n",
            "Gen 6 | Best Fitness: 0.8545\n",
            "Gen 7 | Best Fitness: 0.8545\n",
            "Gen 8 | Best Fitness: 0.8545\n",
            "Gen 9 | Best Fitness: 0.8545\n",
            "Gen 10 | Best Fitness: 0.8545\n",
            "\n",
            "Run with seed 1007\n",
            "Gen 1 | Best Fitness: 0.8510\n",
            "Gen 2 | Best Fitness: 0.8523\n",
            "Gen 3 | Best Fitness: 0.8535\n",
            "Gen 4 | Best Fitness: 0.8535\n",
            "Gen 5 | Best Fitness: 0.8535\n",
            "Gen 6 | Best Fitness: 0.8538\n",
            "Gen 7 | Best Fitness: 0.8538\n",
            "Gen 8 | Best Fitness: 0.8538\n",
            "Gen 9 | Best Fitness: 0.8538\n",
            "Gen 10 | Best Fitness: 0.8538\n",
            "\n",
            "Run with seed 1008\n",
            "Gen 1 | Best Fitness: 0.8538\n",
            "Gen 2 | Best Fitness: 0.8538\n",
            "Gen 3 | Best Fitness: 0.8538\n",
            "Gen 4 | Best Fitness: 0.8540\n",
            "Gen 5 | Best Fitness: 0.8540\n",
            "Gen 6 | Best Fitness: 0.8540\n",
            "Gen 7 | Best Fitness: 0.8540\n",
            "Gen 8 | Best Fitness: 0.8540\n",
            "Gen 9 | Best Fitness: 0.8543\n",
            "Gen 10 | Best Fitness: 0.8543\n",
            "\n",
            "Run with seed 1009\n",
            "Gen 1 | Best Fitness: 0.8330\n",
            "Gen 2 | Best Fitness: 0.8453\n",
            "Gen 3 | Best Fitness: 0.8453\n",
            "Gen 4 | Best Fitness: 0.8473\n",
            "Gen 5 | Best Fitness: 0.8522\n",
            "Gen 6 | Best Fitness: 0.8523\n",
            "Gen 7 | Best Fitness: 0.8525\n",
            "Gen 8 | Best Fitness: 0.8525\n",
            "Gen 9 | Best Fitness: 0.8525\n",
            "Gen 10 | Best Fitness: 0.8525\n",
            "\n",
            "Run with seed 1010\n",
            "Gen 1 | Best Fitness: 0.8508\n",
            "Gen 2 | Best Fitness: 0.8543\n",
            "Gen 3 | Best Fitness: 0.8543\n",
            "Gen 4 | Best Fitness: 0.8543\n",
            "Gen 5 | Best Fitness: 0.8543\n",
            "Gen 6 | Best Fitness: 0.8543\n",
            "Gen 7 | Best Fitness: 0.8550\n",
            "Gen 8 | Best Fitness: 0.8550\n",
            "Gen 9 | Best Fitness: 0.8550\n",
            "Gen 10 | Best Fitness: 0.8550\n",
            "\n",
            "Run with seed 1011\n",
            "Gen 1 | Best Fitness: 0.8448\n",
            "Gen 2 | Best Fitness: 0.8530\n",
            "Gen 3 | Best Fitness: 0.8530\n",
            "Gen 4 | Best Fitness: 0.8568\n",
            "Gen 5 | Best Fitness: 0.8568\n",
            "Gen 6 | Best Fitness: 0.8568\n",
            "Gen 7 | Best Fitness: 0.8568\n",
            "Gen 8 | Best Fitness: 0.8568\n",
            "Gen 9 | Best Fitness: 0.8568\n",
            "Gen 10 | Best Fitness: 0.8568\n",
            "\n",
            "Run with seed 1012\n",
            "Gen 1 | Best Fitness: 0.8518\n",
            "Gen 2 | Best Fitness: 0.8535\n",
            "Gen 3 | Best Fitness: 0.8535\n",
            "Gen 4 | Best Fitness: 0.8535\n",
            "Gen 5 | Best Fitness: 0.8535\n",
            "Gen 6 | Best Fitness: 0.8535\n",
            "Gen 7 | Best Fitness: 0.8543\n",
            "Gen 8 | Best Fitness: 0.8543\n",
            "Gen 9 | Best Fitness: 0.8543\n",
            "Gen 10 | Best Fitness: 0.8543\n",
            "\n",
            "Run with seed 1013\n",
            "Gen 1 | Best Fitness: 0.8535\n",
            "Gen 2 | Best Fitness: 0.8535\n",
            "Gen 3 | Best Fitness: 0.8543\n",
            "Gen 4 | Best Fitness: 0.8543\n",
            "Gen 5 | Best Fitness: 0.8547\n",
            "Gen 6 | Best Fitness: 0.8547\n"
          ]
        }
      ],
      "source": [
        "run_experiments(X_train, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "run_experiments(X_train, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 121,
      "metadata": {},
      "outputs": [],
      "source": [
        "def genetic_algorithm_1(X, y):\n",
        "    all_generations = []\n",
        "    population = create_population(N_POPULATION)\n",
        "    population = evaluate_population(population, X, y)\n",
        "    for individual in population:\n",
        "        all_generations.append({\n",
        "            'generation': 0,\n",
        "            'C': individual[0],\n",
        "            'gamma': individual[1],\n",
        "            'fitness': individual[2]\n",
        "        })\n",
        "    best_solution = max(population, key=lambda x: x[2])\n",
        "    \n",
        "    for iteration in range(N_ITERATIONS):\n",
        "        new_population = []\n",
        "\n",
        "        while len(new_population) < N_POPULATION:\n",
        "            \n",
        "            parent1 = tournament_selection(population)\n",
        "            parent2 = tournament_selection(population)\n",
        "\n",
        "            child = uniform_crossover(parent1, parent2) \n",
        "\n",
        "            child = creep_mutation(child)\n",
        "\n",
        "            child[2] = fitness(child, X, y)\n",
        "\n",
        "            new_population.append(child)\n",
        "\n",
        "        population = new_population\n",
        "        for individual in population:\n",
        "            all_generations.append({\n",
        "                'generation': iteration + 1,\n",
        "                'C': individual[0],\n",
        "                'gamma': individual[1],\n",
        "                'fitness': individual[2]\n",
        "            })\n",
        "\n",
        "        current_best = max(population, key=lambda x: x[2])\n",
        "        if current_best[2] > best_solution[2]:\n",
        "            best_solution = current_best\n",
        "\n",
        "        print(f\"Generation {iteration+1}, Best Accuracy: {best_solution[2]:.4f}\")\n",
        "\n",
        "    return best_solution, all_generations\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 123,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "def genetic_algorithm_1(X, y, run_number):\n",
        "    all_generations = []\n",
        "\n",
        "    population = create_population(N_POPULATION)\n",
        "    population = evaluate_population(population, X, y)\n",
        "\n",
        "    best_solution = max(population, key=lambda x: x[2])\n",
        "\n",
        "    current_best = max(population, key=lambda x: x[2])\n",
        "    all_generations.append({\n",
        "        'run': run_number,\n",
        "        'generation': 0,\n",
        "        'C': current_best[0],\n",
        "        'gamma': current_best[1],\n",
        "        'fitness': current_best[2]\n",
        "    })\n",
        "\n",
        "    for iteration in range(N_ITERATIONS):\n",
        "        new_population = []\n",
        "\n",
        "        while len(new_population) < N_POPULATION:\n",
        "            parent1 = tournament_selection(population)\n",
        "            parent2 = tournament_selection(population)\n",
        "\n",
        "            child = uniform_crossover(parent1, parent2) \n",
        "            child = creep_mutation(child)\n",
        "            child[2] = fitness(child, X, y)\n",
        "\n",
        "            new_population.append(child)\n",
        "\n",
        "        population = new_population\n",
        "\n",
        "        current_best = max(population, key=lambda x: x[2])\n",
        "        if current_best[2] > best_solution[2]:\n",
        "            best_solution = current_best\n",
        "\n",
        "        all_generations.append({\n",
        "            'run': run_number,\n",
        "            'generation': iteration + 1,\n",
        "            'C': current_best[0],\n",
        "            'gamma': current_best[1],\n",
        "            'fitness': current_best[2]\n",
        "        })\n",
        "\n",
        "        print(f\"[Run {run_number}] Generation {iteration+1}, Best Accuracy: {current_best[2]:.4f}\")\n",
        "\n",
        "    return best_solution, all_generations\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 108,
      "metadata": {},
      "outputs": [],
      "source": [
        "def genetic_algorithm_2(X, y):\n",
        "    \n",
        "    population = create_population(N_POPULATION)\n",
        "    population = evaluate_population(population, X, y)\n",
        "\n",
        "    best_solution = max(population, key=lambda x: x[2])\n",
        "    \n",
        "    for iteration in range(N_ITERATIONS):\n",
        "        new_population = []\n",
        "\n",
        "        while len(new_population) < N_POPULATION:\n",
        "            \n",
        "            parent1 = roulette_wheel_selection(population)\n",
        "            parent2 = roulette_wheel_selection(population)\n",
        "\n",
        "            child = uniform_crossover(parent1, parent2)\n",
        "\n",
        "            child = gaussian_mutation(child)\n",
        "\n",
        "            child[2] = fitness(child, X, y)\n",
        "\n",
        "            new_population.append(child)\n",
        "\n",
        "        population = new_population\n",
        "\n",
        "        current_best = max(population, key=lambda x: x[2])\n",
        "        if current_best[2] > best_solution[2]:\n",
        "            best_solution = current_best\n",
        "\n",
        "        print(f\"Generation {iteration+1}, Best Accuracy: {best_solution[2]:.4f}\")\n",
        "\n",
        "    return best_solution\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 208,
      "metadata": {},
      "outputs": [],
      "source": [
        "def genetic_algorithm_3(X, y):\n",
        "    \n",
        "    population = create_population(N_POPULATION)\n",
        "    population = evaluate_population(population, X, y)\n",
        "\n",
        "    best_solution = max(population, key=lambda x: x[2])\n",
        "    \n",
        "    for iteration in range(N_ITERATIONS):\n",
        "        new_population = []\n",
        "\n",
        "        while len(new_population) < N_POPULATION:\n",
        "\n",
        "            parent1 ,parent2 = stochastic_universal_sampling(population)\n",
        "\n",
        "            child = uniform_crossover(parent1, parent2)  \n",
        "\n",
        "            child = creep_mutation(child)\n",
        "\n",
        "            child[2] = fitness(child, X, y)\n",
        "\n",
        "            new_population.append(child)\n",
        "\n",
        "        population = new_population\n",
        "\n",
        "        current_best = max(population, key=lambda x: x[2])\n",
        "        if current_best[2] > best_solution[2]:\n",
        "            best_solution = current_best\n",
        "\n",
        "        print(f\"Generation {iteration+1}, Best Accuracy: {best_solution[2]:.4f}\")\n",
        "\n",
        "    return best_solution\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 110,
      "metadata": {},
      "outputs": [],
      "source": [
        "def genetic_algorithm_4(X, y):\n",
        "    \n",
        "    population = create_population(N_POPULATION)\n",
        "    population = evaluate_population(population, X, y)\n",
        "\n",
        "    best_solution = max(population, key=lambda x: x[2])\n",
        "    \n",
        "    for iteration in range(N_ITERATIONS):\n",
        "        new_population = []\n",
        "\n",
        "        while len(new_population) < N_POPULATION:\n",
        "\n",
        "            parent1 = rank_selection(population)\n",
        "            parent2 = rank_selection(population)\n",
        "\n",
        "            child = uniform_crossover(parent1, parent2)  \n",
        "\n",
        "            child = gaussian_mutation(child)\n",
        "\n",
        "            child[2] = fitness(child, X, y)\n",
        "\n",
        "            new_population.append(child)\n",
        "\n",
        "        population = new_population\n",
        "\n",
        "        current_best = max(population, key=lambda x: x[2])\n",
        "        if current_best[2] > best_solution[2]:\n",
        "            best_solution = current_best\n",
        "\n",
        "        print(f\"Generation {iteration+1}, Best Accuracy: {best_solution[2]:.4f}\")\n",
        "\n",
        "    return best_solution\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 203,
      "metadata": {},
      "outputs": [],
      "source": [
        "def genetic_algorithm_5(X, y):\n",
        "    \n",
        "    population = create_population(N_POPULATION)\n",
        "    population = evaluate_population(population, X, y)\n",
        "\n",
        "    best_solution = max(population, key=lambda x: x[2])\n",
        "    \n",
        "    for iteration in range(N_ITERATIONS):\n",
        "        new_population = []\n",
        "\n",
        "        while len(new_population) < N_POPULATION:\n",
        "\n",
        "            parent1 = roulette_wheel_selection(population)\n",
        "            parent2 = rank_selection(population)\n",
        "\n",
        "            child = uniform_crossover(parent1, parent2)  \n",
        "\n",
        "            child = gaussian_mutation(child)\n",
        "\n",
        "            child[2] = fitness(child, X, y)\n",
        "\n",
        "            new_population.append(child)\n",
        "\n",
        "        population = new_population\n",
        "\n",
        "        current_best = max(population, key=lambda x: x[2])\n",
        "        if current_best[2] > best_solution[2]:\n",
        "            best_solution = current_best\n",
        "\n",
        "        print(f\"Generation {iteration+1}, Best Accuracy: {best_solution[2]:.4f}\")\n",
        "\n",
        "    return best_solution"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 126,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Run 1] Generation 1, Best Accuracy: 0.8538\n",
            "[Run 1] Generation 2, Best Accuracy: 0.8538\n",
            "[Run 1] Generation 3, Best Accuracy: 0.8543\n",
            "[Run 1] Generation 4, Best Accuracy: 0.8543\n",
            "[Run 1] Generation 5, Best Accuracy: 0.8543\n",
            "[Run 2] Generation 1, Best Accuracy: 0.8492\n",
            "[Run 2] Generation 2, Best Accuracy: 0.8530\n",
            "[Run 2] Generation 3, Best Accuracy: 0.8557\n",
            "[Run 2] Generation 4, Best Accuracy: 0.8540\n",
            "[Run 2] Generation 5, Best Accuracy: 0.8530\n",
            "[Run 3] Generation 1, Best Accuracy: 0.8538\n",
            "[Run 3] Generation 2, Best Accuracy: 0.8543\n",
            "[Run 3] Generation 3, Best Accuracy: 0.8543\n",
            "[Run 3] Generation 4, Best Accuracy: 0.8550\n",
            "[Run 3] Generation 5, Best Accuracy: 0.8550\n",
            "[Run 4] Generation 1, Best Accuracy: 0.8535\n",
            "[Run 4] Generation 2, Best Accuracy: 0.8538\n",
            "[Run 4] Generation 3, Best Accuracy: 0.8540\n",
            "[Run 4] Generation 4, Best Accuracy: 0.8545\n",
            "[Run 4] Generation 5, Best Accuracy: 0.8545\n",
            "[Run 5] Generation 1, Best Accuracy: 0.8538\n",
            "[Run 5] Generation 2, Best Accuracy: 0.8538\n",
            "[Run 5] Generation 3, Best Accuracy: 0.8538\n",
            "[Run 5] Generation 4, Best Accuracy: 0.8543\n",
            "[Run 5] Generation 5, Best Accuracy: 0.8543\n",
            "[Run 6] Generation 1, Best Accuracy: 0.8538\n",
            "[Run 6] Generation 2, Best Accuracy: 0.8538\n",
            "[Run 6] Generation 3, Best Accuracy: 0.8543\n",
            "[Run 6] Generation 4, Best Accuracy: 0.8543\n",
            "[Run 6] Generation 5, Best Accuracy: 0.8543\n",
            "[Run 7] Generation 1, Best Accuracy: 0.8518\n",
            "[Run 7] Generation 2, Best Accuracy: 0.8525\n",
            "[Run 7] Generation 3, Best Accuracy: 0.8540\n",
            "[Run 7] Generation 4, Best Accuracy: 0.8540\n",
            "[Run 7] Generation 5, Best Accuracy: 0.8540\n",
            "[Run 8] Generation 1, Best Accuracy: 0.8528\n",
            "[Run 8] Generation 2, Best Accuracy: 0.8547\n",
            "[Run 8] Generation 3, Best Accuracy: 0.8553\n",
            "[Run 8] Generation 4, Best Accuracy: 0.8553\n",
            "[Run 8] Generation 5, Best Accuracy: 0.8553\n",
            "[Run 9] Generation 1, Best Accuracy: 0.8535\n",
            "[Run 9] Generation 2, Best Accuracy: 0.8545\n",
            "[Run 9] Generation 3, Best Accuracy: 0.8545\n",
            "[Run 9] Generation 4, Best Accuracy: 0.8545\n",
            "[Run 9] Generation 5, Best Accuracy: 0.8548\n",
            "[Run 10] Generation 1, Best Accuracy: 0.8525\n",
            "[Run 10] Generation 2, Best Accuracy: 0.8550\n",
            "[Run 10] Generation 3, Best Accuracy: 0.8538\n",
            "[Run 10] Generation 4, Best Accuracy: 0.8543\n",
            "[Run 10] Generation 5, Best Accuracy: 0.8543\n",
            "[Run 11] Generation 1, Best Accuracy: 0.8488\n",
            "[Run 11] Generation 2, Best Accuracy: 0.8532\n",
            "[Run 11] Generation 3, Best Accuracy: 0.8538\n",
            "[Run 11] Generation 4, Best Accuracy: 0.8540\n",
            "[Run 11] Generation 5, Best Accuracy: 0.8540\n",
            "[Run 12] Generation 1, Best Accuracy: 0.8553\n",
            "[Run 12] Generation 2, Best Accuracy: 0.8553\n",
            "[Run 12] Generation 3, Best Accuracy: 0.8553\n",
            "[Run 12] Generation 4, Best Accuracy: 0.8553\n",
            "[Run 12] Generation 5, Best Accuracy: 0.8553\n",
            "[Run 13] Generation 1, Best Accuracy: 0.8555\n",
            "[Run 13] Generation 2, Best Accuracy: 0.8565\n",
            "[Run 13] Generation 3, Best Accuracy: 0.8565\n",
            "[Run 13] Generation 4, Best Accuracy: 0.8565\n",
            "[Run 13] Generation 5, Best Accuracy: 0.8565\n",
            "[Run 14] Generation 1, Best Accuracy: 0.8528\n",
            "[Run 14] Generation 2, Best Accuracy: 0.8538\n",
            "[Run 14] Generation 3, Best Accuracy: 0.8540\n",
            "[Run 14] Generation 4, Best Accuracy: 0.8545\n",
            "[Run 14] Generation 5, Best Accuracy: 0.8547\n",
            "[Run 15] Generation 1, Best Accuracy: 0.8512\n",
            "[Run 15] Generation 2, Best Accuracy: 0.8542\n",
            "[Run 15] Generation 3, Best Accuracy: 0.8542\n",
            "[Run 15] Generation 4, Best Accuracy: 0.8542\n",
            "[Run 15] Generation 5, Best Accuracy: 0.8547\n",
            "[Run 16] Generation 1, Best Accuracy: 0.8550\n",
            "[Run 16] Generation 2, Best Accuracy: 0.8550\n",
            "[Run 16] Generation 3, Best Accuracy: 0.8550\n",
            "[Run 16] Generation 4, Best Accuracy: 0.8550\n",
            "[Run 16] Generation 5, Best Accuracy: 0.8550\n",
            "[Run 17] Generation 1, Best Accuracy: 0.8520\n",
            "[Run 17] Generation 2, Best Accuracy: 0.8533\n",
            "[Run 17] Generation 3, Best Accuracy: 0.8538\n",
            "[Run 17] Generation 4, Best Accuracy: 0.8540\n",
            "[Run 17] Generation 5, Best Accuracy: 0.8540\n",
            "[Run 18] Generation 1, Best Accuracy: 0.8522\n",
            "[Run 18] Generation 2, Best Accuracy: 0.8540\n",
            "[Run 18] Generation 3, Best Accuracy: 0.8530\n",
            "[Run 18] Generation 4, Best Accuracy: 0.8538\n",
            "[Run 18] Generation 5, Best Accuracy: 0.8538\n",
            "[Run 19] Generation 1, Best Accuracy: 0.8543\n",
            "[Run 19] Generation 2, Best Accuracy: 0.8543\n",
            "[Run 19] Generation 3, Best Accuracy: 0.8543\n",
            "[Run 19] Generation 4, Best Accuracy: 0.8547\n",
            "[Run 19] Generation 5, Best Accuracy: 0.8547\n",
            "[Run 20] Generation 1, Best Accuracy: 0.8545\n",
            "[Run 20] Generation 2, Best Accuracy: 0.8545\n",
            "[Run 20] Generation 3, Best Accuracy: 0.8553\n",
            "[Run 20] Generation 4, Best Accuracy: 0.8553\n",
            "[Run 20] Generation 5, Best Accuracy: 0.8553\n",
            "[Run 21] Generation 1, Best Accuracy: 0.8525\n",
            "[Run 21] Generation 2, Best Accuracy: 0.8553\n",
            "[Run 21] Generation 3, Best Accuracy: 0.8553\n",
            "[Run 21] Generation 4, Best Accuracy: 0.8553\n",
            "[Run 21] Generation 5, Best Accuracy: 0.8553\n",
            "[Run 22] Generation 1, Best Accuracy: 0.8532\n",
            "[Run 22] Generation 2, Best Accuracy: 0.8542\n",
            "[Run 22] Generation 3, Best Accuracy: 0.8550\n",
            "[Run 22] Generation 4, Best Accuracy: 0.8550\n",
            "[Run 22] Generation 5, Best Accuracy: 0.8550\n",
            "[Run 23] Generation 1, Best Accuracy: 0.8515\n",
            "[Run 23] Generation 2, Best Accuracy: 0.8528\n",
            "[Run 23] Generation 3, Best Accuracy: 0.8532\n",
            "[Run 23] Generation 4, Best Accuracy: 0.8533\n",
            "[Run 23] Generation 5, Best Accuracy: 0.8533\n",
            "[Run 24] Generation 1, Best Accuracy: 0.8533\n",
            "[Run 24] Generation 2, Best Accuracy: 0.8533\n",
            "[Run 24] Generation 3, Best Accuracy: 0.8553\n",
            "[Run 24] Generation 4, Best Accuracy: 0.8553\n",
            "[Run 24] Generation 5, Best Accuracy: 0.8533\n",
            "[Run 25] Generation 1, Best Accuracy: 0.8545\n",
            "[Run 25] Generation 2, Best Accuracy: 0.8545\n",
            "[Run 25] Generation 3, Best Accuracy: 0.8545\n",
            "[Run 25] Generation 4, Best Accuracy: 0.8545\n",
            "[Run 25] Generation 5, Best Accuracy: 0.8545\n",
            "[Run 26] Generation 1, Best Accuracy: 0.8500\n",
            "[Run 26] Generation 2, Best Accuracy: 0.8545\n",
            "[Run 26] Generation 3, Best Accuracy: 0.8545\n",
            "[Run 26] Generation 4, Best Accuracy: 0.8545\n",
            "[Run 26] Generation 5, Best Accuracy: 0.8545\n",
            "[Run 27] Generation 1, Best Accuracy: 0.8530\n",
            "[Run 27] Generation 2, Best Accuracy: 0.8530\n",
            "[Run 27] Generation 3, Best Accuracy: 0.8532\n",
            "[Run 27] Generation 4, Best Accuracy: 0.8535\n",
            "[Run 27] Generation 5, Best Accuracy: 0.8535\n",
            "[Run 28] Generation 1, Best Accuracy: 0.8502\n",
            "[Run 28] Generation 2, Best Accuracy: 0.8515\n",
            "[Run 28] Generation 3, Best Accuracy: 0.8515\n",
            "[Run 28] Generation 4, Best Accuracy: 0.8515\n",
            "[Run 28] Generation 5, Best Accuracy: 0.8515\n",
            "[Run 29] Generation 1, Best Accuracy: 0.8550\n",
            "[Run 29] Generation 2, Best Accuracy: 0.8550\n",
            "[Run 29] Generation 3, Best Accuracy: 0.8550\n",
            "[Run 29] Generation 4, Best Accuracy: 0.8550\n",
            "[Run 29] Generation 5, Best Accuracy: 0.8550\n",
            "[Run 30] Generation 1, Best Accuracy: 0.8550\n",
            "[Run 30] Generation 2, Best Accuracy: 0.8550\n",
            "[Run 30] Generation 3, Best Accuracy: 0.8550\n",
            "[Run 30] Generation 4, Best Accuracy: 0.8550\n",
            "[Run 30] Generation 5, Best Accuracy: 0.8550\n"
          ]
        }
      ],
      "source": [
        "all_runs_data = []\n",
        "\n",
        "for run in range(1, 31):\n",
        "    _, run_data = genetic_algorithm_1(X_train, y_train, run)\n",
        "    all_runs_data.extend(run_data)\n",
        "\n",
        "\n",
        "df = pd.DataFrame(all_runs_data)\n",
        "df.to_csv(\"Best_Per_Generation_30_Runs.csv\", index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 114,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generation 1, Best Accuracy: 0.8432\n",
            "Generation 2, Best Accuracy: 0.8432\n",
            "Generation 3, Best Accuracy: 0.8432\n",
            "Generation 4, Best Accuracy: 0.8432\n",
            "Generation 5, Best Accuracy: 0.8432\n",
            "Generation 6, Best Accuracy: 0.8432\n",
            "Generation 7, Best Accuracy: 0.8432\n",
            "Generation 8, Best Accuracy: 0.8432\n",
            "Generation 9, Best Accuracy: 0.8432\n",
            "Generation 10, Best Accuracy: 0.8432\n",
            "Generation 11, Best Accuracy: 0.8432\n",
            "Generation 12, Best Accuracy: 0.8432\n",
            "Generation 13, Best Accuracy: 0.8432\n",
            "Generation 14, Best Accuracy: 0.8432\n",
            "Generation 15, Best Accuracy: 0.8432\n",
            "Generation 16, Best Accuracy: 0.8432\n",
            "Generation 17, Best Accuracy: 0.8432\n",
            "Generation 18, Best Accuracy: 0.8432\n",
            "Generation 19, Best Accuracy: 0.8432\n",
            "Generation 20, Best Accuracy: 0.8432\n",
            "Generation 21, Best Accuracy: 0.8432\n",
            "Generation 22, Best Accuracy: 0.8432\n",
            "Generation 23, Best Accuracy: 0.8432\n",
            "Generation 24, Best Accuracy: 0.8432\n",
            "Generation 25, Best Accuracy: 0.8432\n",
            "Generation 26, Best Accuracy: 0.8432\n",
            "Generation 27, Best Accuracy: 0.8432\n",
            "Generation 28, Best Accuracy: 0.8432\n",
            "Generation 29, Best Accuracy: 0.8432\n",
            "Generation 30, Best Accuracy: 0.8432\n",
            "[3.7760001260774683, 0.13843756461445222, np.float64(0.8432499999999999)]\n"
          ]
        }
      ],
      "source": [
        "best = genetic_algorithm_2(X_train, y_train)\n",
        "print(best)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 209,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generation 1, Best Accuracy: 0.8218\n",
            "Generation 2, Best Accuracy: 0.8218\n",
            "Generation 3, Best Accuracy: 0.8218\n",
            "Generation 4, Best Accuracy: 0.8218\n",
            "Generation 5, Best Accuracy: 0.8218\n",
            "Generation 6, Best Accuracy: 0.8218\n",
            "Generation 7, Best Accuracy: 0.8218\n",
            "Generation 8, Best Accuracy: 0.8218\n",
            "Generation 9, Best Accuracy: 0.8218\n",
            "Generation 10, Best Accuracy: 0.8218\n",
            "Generation 11, Best Accuracy: 0.8218\n",
            "Generation 12, Best Accuracy: 0.8218\n",
            "Generation 13, Best Accuracy: 0.8218\n",
            "Generation 14, Best Accuracy: 0.8218\n",
            "Generation 15, Best Accuracy: 0.8218\n",
            "Generation 16, Best Accuracy: 0.8218\n",
            "Generation 17, Best Accuracy: 0.8218\n",
            "Generation 18, Best Accuracy: 0.8218\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[209], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m best \u001b[38;5;241m=\u001b[39m \u001b[43mgenetic_algorithm_3\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(best)\n",
            "Cell \u001b[1;32mIn[208], line 19\u001b[0m, in \u001b[0;36mgenetic_algorithm_3\u001b[1;34m(X, y)\u001b[0m\n\u001b[0;32m     15\u001b[0m     child \u001b[38;5;241m=\u001b[39m uniform_crossover(parent1, parent2)  \n\u001b[0;32m     17\u001b[0m     child \u001b[38;5;241m=\u001b[39m creep_mutation(child)\n\u001b[1;32m---> 19\u001b[0m     child[\u001b[38;5;241m2\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mfitness\u001b[49m\u001b[43m(\u001b[49m\u001b[43mchild\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     21\u001b[0m     new_population\u001b[38;5;241m.\u001b[39mappend(child)\n\u001b[0;32m     23\u001b[0m population \u001b[38;5;241m=\u001b[39m new_population\n",
            "Cell \u001b[1;32mIn[94], line 9\u001b[0m, in \u001b[0;36mfitness\u001b[1;34m(chromosome, X, y)\u001b[0m\n\u001b[0;32m      2\u001b[0m C, gamma \u001b[38;5;241m=\u001b[39m chromosome[\u001b[38;5;241m0\u001b[39m] ,chromosome[\u001b[38;5;241m1\u001b[39m]\n\u001b[0;32m      4\u001b[0m model \u001b[38;5;241m=\u001b[39m Pipeline([\n\u001b[0;32m      5\u001b[0m     (\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpreprocessor\u001b[39m\u001b[38;5;124m'\u001b[39m, preprocessor),\n\u001b[0;32m      6\u001b[0m     (\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msvc\u001b[39m\u001b[38;5;124m'\u001b[39m, SVC(C\u001b[38;5;241m=\u001b[39mC, gamma\u001b[38;5;241m=\u001b[39mgamma, kernel\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrbf\u001b[39m\u001b[38;5;124m'\u001b[39m))\n\u001b[0;32m      7\u001b[0m ])\n\u001b[1;32m----> 9\u001b[0m scores \u001b[38;5;241m=\u001b[39m \u001b[43mcross_val_score\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcv\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m scores\u001b[38;5;241m.\u001b[39mmean()\n",
            "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\utils\\_param_validation.py:216\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    210\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    211\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m    212\u001b[0m         skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m    213\u001b[0m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m    214\u001b[0m         )\n\u001b[0;32m    215\u001b[0m     ):\n\u001b[1;32m--> 216\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    217\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    218\u001b[0m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[0;32m    219\u001b[0m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[0;32m    220\u001b[0m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[0;32m    221\u001b[0m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[0;32m    222\u001b[0m     msg \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39msub(\n\u001b[0;32m    223\u001b[0m         \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mw+ must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    224\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    225\u001b[0m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[0;32m    226\u001b[0m     )\n",
            "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\model_selection\\_validation.py:684\u001b[0m, in \u001b[0;36mcross_val_score\u001b[1;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, params, pre_dispatch, error_score)\u001b[0m\n\u001b[0;32m    681\u001b[0m \u001b[38;5;66;03m# To ensure multimetric format is not supported\u001b[39;00m\n\u001b[0;32m    682\u001b[0m scorer \u001b[38;5;241m=\u001b[39m check_scoring(estimator, scoring\u001b[38;5;241m=\u001b[39mscoring)\n\u001b[1;32m--> 684\u001b[0m cv_results \u001b[38;5;241m=\u001b[39m \u001b[43mcross_validate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    685\u001b[0m \u001b[43m    \u001b[49m\u001b[43mestimator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    686\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    687\u001b[0m \u001b[43m    \u001b[49m\u001b[43my\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    688\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgroups\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroups\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    689\u001b[0m \u001b[43m    \u001b[49m\u001b[43mscoring\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mscore\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mscorer\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    690\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcv\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcv\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    691\u001b[0m \u001b[43m    \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    692\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    693\u001b[0m \u001b[43m    \u001b[49m\u001b[43mparams\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    694\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpre_dispatch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpre_dispatch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    695\u001b[0m \u001b[43m    \u001b[49m\u001b[43merror_score\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merror_score\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    696\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    697\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m cv_results[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest_score\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
            "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\utils\\_param_validation.py:216\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    210\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    211\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m    212\u001b[0m         skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m    213\u001b[0m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m    214\u001b[0m         )\n\u001b[0;32m    215\u001b[0m     ):\n\u001b[1;32m--> 216\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    217\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    218\u001b[0m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[0;32m    219\u001b[0m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[0;32m    220\u001b[0m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[0;32m    221\u001b[0m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[0;32m    222\u001b[0m     msg \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39msub(\n\u001b[0;32m    223\u001b[0m         \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mw+ must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    224\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    225\u001b[0m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[0;32m    226\u001b[0m     )\n",
            "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\model_selection\\_validation.py:411\u001b[0m, in \u001b[0;36mcross_validate\u001b[1;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, params, pre_dispatch, return_train_score, return_estimator, return_indices, error_score)\u001b[0m\n\u001b[0;32m    408\u001b[0m \u001b[38;5;66;03m# We clone the estimator to make sure that all the folds are\u001b[39;00m\n\u001b[0;32m    409\u001b[0m \u001b[38;5;66;03m# independent, and that it is pickle-able.\u001b[39;00m\n\u001b[0;32m    410\u001b[0m parallel \u001b[38;5;241m=\u001b[39m Parallel(n_jobs\u001b[38;5;241m=\u001b[39mn_jobs, verbose\u001b[38;5;241m=\u001b[39mverbose, pre_dispatch\u001b[38;5;241m=\u001b[39mpre_dispatch)\n\u001b[1;32m--> 411\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[43mparallel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    412\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_fit_and_score\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    413\u001b[0m \u001b[43m        \u001b[49m\u001b[43mclone\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    414\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    415\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    416\u001b[0m \u001b[43m        \u001b[49m\u001b[43mscorer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mscorers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    417\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrain\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    418\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtest\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    419\u001b[0m \u001b[43m        \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    420\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparameters\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    421\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfit_params\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrouted_params\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mestimator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    422\u001b[0m \u001b[43m        \u001b[49m\u001b[43mscore_params\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrouted_params\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mscorer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mscore\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    423\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_train_score\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_train_score\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    424\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_times\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    425\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_estimator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_estimator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    426\u001b[0m \u001b[43m        \u001b[49m\u001b[43merror_score\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merror_score\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    427\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    428\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mindices\u001b[49m\n\u001b[0;32m    429\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    431\u001b[0m _warn_or_raise_about_fit_failures(results, error_score)\n\u001b[0;32m    433\u001b[0m \u001b[38;5;66;03m# For callable scoring, the return type is only know after calling. If the\u001b[39;00m\n\u001b[0;32m    434\u001b[0m \u001b[38;5;66;03m# return type is a dictionary, the error scores can now be inserted with\u001b[39;00m\n\u001b[0;32m    435\u001b[0m \u001b[38;5;66;03m# the correct key.\u001b[39;00m\n",
            "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\utils\\parallel.py:77\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m     72\u001b[0m config \u001b[38;5;241m=\u001b[39m get_config()\n\u001b[0;32m     73\u001b[0m iterable_with_config \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m     74\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[0;32m     75\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[0;32m     76\u001b[0m )\n\u001b[1;32m---> 77\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43miterable_with_config\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\joblib\\parallel.py:1918\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1916\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_sequential_output(iterable)\n\u001b[0;32m   1917\u001b[0m     \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[1;32m-> 1918\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturn_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1920\u001b[0m \u001b[38;5;66;03m# Let's create an ID that uniquely identifies the current call. If the\u001b[39;00m\n\u001b[0;32m   1921\u001b[0m \u001b[38;5;66;03m# call is interrupted early and that the same instance is immediately\u001b[39;00m\n\u001b[0;32m   1922\u001b[0m \u001b[38;5;66;03m# re-used, this id will be used to prevent workers that were\u001b[39;00m\n\u001b[0;32m   1923\u001b[0m \u001b[38;5;66;03m# concurrently finalizing a task from the previous call to run the\u001b[39;00m\n\u001b[0;32m   1924\u001b[0m \u001b[38;5;66;03m# callback.\u001b[39;00m\n\u001b[0;32m   1925\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n",
            "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\joblib\\parallel.py:1847\u001b[0m, in \u001b[0;36mParallel._get_sequential_output\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1845\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_dispatched_batches \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m   1846\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_dispatched_tasks \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m-> 1847\u001b[0m res \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1848\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_completed_tasks \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m   1849\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprint_progress()\n",
            "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\utils\\parallel.py:139\u001b[0m, in \u001b[0;36m_FuncWrapper.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    137\u001b[0m     config \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m    138\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mconfig):\n\u001b[1;32m--> 139\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunction\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\model_selection\\_validation.py:888\u001b[0m, in \u001b[0;36m_fit_and_score\u001b[1;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, score_params, return_train_score, return_parameters, return_n_test_samples, return_times, return_estimator, split_progress, candidate_progress, error_score)\u001b[0m\n\u001b[0;32m    885\u001b[0m result[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfit_error\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    887\u001b[0m fit_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m-\u001b[39m start_time\n\u001b[1;32m--> 888\u001b[0m test_scores \u001b[38;5;241m=\u001b[39m \u001b[43m_score\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    889\u001b[0m \u001b[43m    \u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscorer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscore_params_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merror_score\u001b[49m\n\u001b[0;32m    890\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    891\u001b[0m score_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m-\u001b[39m start_time \u001b[38;5;241m-\u001b[39m fit_time\n\u001b[0;32m    892\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m return_train_score:\n",
            "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\model_selection\\_validation.py:949\u001b[0m, in \u001b[0;36m_score\u001b[1;34m(estimator, X_test, y_test, scorer, score_params, error_score)\u001b[0m\n\u001b[0;32m    947\u001b[0m         scores \u001b[38;5;241m=\u001b[39m scorer(estimator, X_test, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mscore_params)\n\u001b[0;32m    948\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 949\u001b[0m         scores \u001b[38;5;241m=\u001b[39m \u001b[43mscorer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mscore_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    950\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[0;32m    951\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(scorer, _MultimetricScorer):\n\u001b[0;32m    952\u001b[0m         \u001b[38;5;66;03m# If `_MultimetricScorer` raises exception, the `error_score`\u001b[39;00m\n\u001b[0;32m    953\u001b[0m         \u001b[38;5;66;03m# parameter is equal to \"raise\".\u001b[39;00m\n",
            "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_scorer.py:144\u001b[0m, in \u001b[0;36m_MultimetricScorer.__call__\u001b[1;34m(self, estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m    140\u001b[0m         score \u001b[38;5;241m=\u001b[39m scorer\u001b[38;5;241m.\u001b[39m_score(\n\u001b[0;32m    141\u001b[0m             cached_call, estimator, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mrouted_params\u001b[38;5;241m.\u001b[39mget(name)\u001b[38;5;241m.\u001b[39mscore\n\u001b[0;32m    142\u001b[0m         )\n\u001b[0;32m    143\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 144\u001b[0m         score \u001b[38;5;241m=\u001b[39m \u001b[43mscorer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mrouted_params\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mscore\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    145\u001b[0m     scores[name] \u001b[38;5;241m=\u001b[39m score\n\u001b[0;32m    146\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
            "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_scorer.py:472\u001b[0m, in \u001b[0;36m_PassthroughScorer.__call__\u001b[1;34m(self, estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m    470\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, estimator, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m    471\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Method that wraps estimator.score\"\"\"\u001b[39;00m\n\u001b[1;32m--> 472\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mestimator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mscore\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\pipeline.py:1199\u001b[0m, in \u001b[0;36mPipeline.score\u001b[1;34m(self, X, y, sample_weight, **params)\u001b[0m\n\u001b[0;32m   1197\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m sample_weight \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   1198\u001b[0m         score_params[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msample_weight\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m sample_weight\n\u001b[1;32m-> 1199\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msteps\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mscore\u001b[49m\u001b[43m(\u001b[49m\u001b[43mXt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mscore_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1201\u001b[0m \u001b[38;5;66;03m# metadata routing is enabled.\u001b[39;00m\n\u001b[0;32m   1202\u001b[0m routed_params \u001b[38;5;241m=\u001b[39m process_routing(\n\u001b[0;32m   1203\u001b[0m     \u001b[38;5;28mself\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mscore\u001b[39m\u001b[38;5;124m\"\u001b[39m, sample_weight\u001b[38;5;241m=\u001b[39msample_weight, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mparams\n\u001b[0;32m   1204\u001b[0m )\n",
            "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\base.py:572\u001b[0m, in \u001b[0;36mClassifierMixin.score\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    547\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    548\u001b[0m \u001b[38;5;124;03mReturn the mean accuracy on the given test data and labels.\u001b[39;00m\n\u001b[0;32m    549\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    568\u001b[0m \u001b[38;5;124;03m    Mean accuracy of ``self.predict(X)`` w.r.t. `y`.\u001b[39;00m\n\u001b[0;32m    569\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    570\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmetrics\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m accuracy_score\n\u001b[1;32m--> 572\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m accuracy_score(y, \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m, sample_weight\u001b[38;5;241m=\u001b[39msample_weight)\n",
            "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\svm\\_base.py:822\u001b[0m, in \u001b[0;36mBaseSVC.predict\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    820\u001b[0m     y \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39margmax(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdecision_function(X), axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m    821\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 822\u001b[0m     y \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    823\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclasses_\u001b[38;5;241m.\u001b[39mtake(np\u001b[38;5;241m.\u001b[39masarray(y, dtype\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39mintp))\n",
            "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\svm\\_base.py:438\u001b[0m, in \u001b[0;36mBaseLibSVM.predict\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    436\u001b[0m X \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_for_predict(X)\n\u001b[0;32m    437\u001b[0m predict \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sparse_predict \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sparse \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dense_predict\n\u001b[1;32m--> 438\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\svm\\_base.py:484\u001b[0m, in \u001b[0;36mBaseLibSVM._sparse_predict\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    480\u001b[0m kernel_type \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sparse_kernels\u001b[38;5;241m.\u001b[39mindex(kernel)\n\u001b[0;32m    482\u001b[0m C \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.0\u001b[39m  \u001b[38;5;66;03m# C is not useful here\u001b[39;00m\n\u001b[1;32m--> 484\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mlibsvm_sparse\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlibsvm_sparse_predict\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    485\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    486\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindices\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    487\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindptr\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    488\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msupport_vectors_\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    489\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msupport_vectors_\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindices\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    490\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msupport_vectors_\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindptr\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    491\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dual_coef_\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    492\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_intercept_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    493\u001b[0m \u001b[43m    \u001b[49m\u001b[43mLIBSVM_IMPL\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindex\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_impl\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    494\u001b[0m \u001b[43m    \u001b[49m\u001b[43mkernel_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    495\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdegree\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    496\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_gamma\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    497\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcoef0\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    498\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtol\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    499\u001b[0m \u001b[43m    \u001b[49m\u001b[43mC\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    500\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mclass_weight_\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mempty\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    501\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnu\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    502\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mepsilon\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    503\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshrinking\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    504\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprobability\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    505\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_n_support\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    506\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_probA\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    507\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_probB\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    508\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "best = genetic_algorithm_3(X_train, y_train)\n",
        "print(best)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 116,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generation 1, Best Accuracy: 0.8465\n",
            "Generation 2, Best Accuracy: 0.8465\n",
            "Generation 3, Best Accuracy: 0.8465\n",
            "Generation 4, Best Accuracy: 0.8465\n",
            "Generation 5, Best Accuracy: 0.8465\n",
            "Generation 6, Best Accuracy: 0.8465\n",
            "Generation 7, Best Accuracy: 0.8465\n",
            "Generation 8, Best Accuracy: 0.8465\n",
            "Generation 9, Best Accuracy: 0.8465\n",
            "Generation 10, Best Accuracy: 0.8465\n",
            "Generation 11, Best Accuracy: 0.8465\n",
            "Generation 12, Best Accuracy: 0.8465\n",
            "Generation 13, Best Accuracy: 0.8465\n",
            "Generation 14, Best Accuracy: 0.8465\n",
            "Generation 15, Best Accuracy: 0.8465\n",
            "Generation 16, Best Accuracy: 0.8465\n",
            "Generation 17, Best Accuracy: 0.8465\n",
            "Generation 18, Best Accuracy: 0.8465\n",
            "Generation 19, Best Accuracy: 0.8465\n",
            "Generation 20, Best Accuracy: 0.8465\n",
            "Generation 21, Best Accuracy: 0.8465\n",
            "Generation 22, Best Accuracy: 0.8465\n",
            "Generation 23, Best Accuracy: 0.8465\n",
            "Generation 24, Best Accuracy: 0.8465\n",
            "Generation 25, Best Accuracy: 0.8465\n",
            "Generation 26, Best Accuracy: 0.8465\n",
            "Generation 27, Best Accuracy: 0.8465\n",
            "Generation 28, Best Accuracy: 0.8465\n",
            "Generation 29, Best Accuracy: 0.8465\n",
            "Generation 30, Best Accuracy: 0.8465\n",
            "[78.33782518013194, 0.018788554956062145, np.float64(0.8465)]\n"
          ]
        }
      ],
      "source": [
        "best = genetic_algorithm_4(X_train, y_train)\n",
        "print(best)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 118,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generation 1, Best Accuracy: 0.8497\n",
            "Generation 2, Best Accuracy: 0.8497\n",
            "Generation 3, Best Accuracy: 0.8547\n",
            "Generation 4, Best Accuracy: 0.8547\n",
            "Generation 5, Best Accuracy: 0.8547\n",
            "Generation 6, Best Accuracy: 0.8547\n",
            "Generation 7, Best Accuracy: 0.8547\n",
            "Generation 8, Best Accuracy: 0.8547\n",
            "Generation 9, Best Accuracy: 0.8547\n",
            "Generation 10, Best Accuracy: 0.8547\n",
            "Generation 11, Best Accuracy: 0.8547\n",
            "Generation 12, Best Accuracy: 0.8547\n",
            "Generation 13, Best Accuracy: 0.8547\n",
            "Generation 14, Best Accuracy: 0.8547\n",
            "Generation 15, Best Accuracy: 0.8547\n",
            "Generation 16, Best Accuracy: 0.8547\n",
            "Generation 17, Best Accuracy: 0.8547\n",
            "Generation 18, Best Accuracy: 0.8547\n",
            "Generation 19, Best Accuracy: 0.8547\n",
            "Generation 20, Best Accuracy: 0.8547\n",
            "Generation 21, Best Accuracy: 0.8547\n",
            "Generation 22, Best Accuracy: 0.8547\n",
            "Generation 23, Best Accuracy: 0.8547\n",
            "Generation 24, Best Accuracy: 0.8547\n",
            "Generation 25, Best Accuracy: 0.8547\n",
            "Generation 26, Best Accuracy: 0.8547\n",
            "Generation 27, Best Accuracy: 0.8547\n",
            "Generation 28, Best Accuracy: 0.8547\n",
            "Generation 29, Best Accuracy: 0.8547\n",
            "Generation 30, Best Accuracy: 0.8547\n",
            "[29.962697249386725, 0.004650758625611051, np.float64(0.8547499999999999)]\n"
          ]
        }
      ],
      "source": [
        "best = genetic_algorithm_5(X_train, y_train)\n",
        "print(best)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.8"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
